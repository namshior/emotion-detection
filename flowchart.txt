1. Importing the Packages
2. Loading the Dataset
3. Data Processing
	- Dropping the duplicates
	- Cleaning the Text
		- Cleaning the emojis
		- Remove the Punctuations, links, mention
	- Cleaning the hashtags
	- filtering out the special characters
	- removing all multiple spaces
4. Visualization using Seaborn and Matplotlib
5. Tokenization using 
	- Tfidf Vectorizer
6. Feature Selection 
7. Splitting the data to train and test
8. Building the model
    	- Random Forest
	- SVM
	- KNN
	- XGBoost Classifier 
	- RF + DT
	- XGB + DT
	- SVM + DT
	- RF + XGB
	- RF + SVM
	- XGB + SVM
	- SMOTE + Systematic Analysis + Sentiment FEature(RF + SVM + XGB)
10. Training the model
11. Building the model 
12. Flask Framework with Sqlite for signup and signin
13. Importing the packages
14. Exploring the dataset
15. Processing and training the data 
16. User gives input 
17. The given input is translated and preprocessed for prediction
18. Trained model is used for prediction
19. Final outcome is displayed through frontend
Extension:
In the base paper, the author mentioned to use different ML for analysis the dataset, Got 90% of accuracy,
as an extension we applied LDA model for Topic Modeling the input
The build model is used to predict and Topic Modelling for user input in the Flask Framework.
